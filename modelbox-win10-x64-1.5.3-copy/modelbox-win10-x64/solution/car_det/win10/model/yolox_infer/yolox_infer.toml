# Copyright (c) Huawei Technologies Co., Ltd. 2022. All rights reserved.

[base]
name = "yolox_infer"
device = "cpu"
version = "1.0.0"
description = "car detection"
entry = "./yolox_nano_288x512.onnx"  # model file path, use relative path
type = "inference" 
virtual_type = "onnx" # inference engine type: win10 now only support onnx
group_type = "Inference"  # flowunit group attribution, do not change


# input port description, suporrt multiple input ports
[input]
[input.input1]
name = "input"
type = "float"
device = "cpu"

# output port description, suporrt multiple output ports
[output]
[output.output1]
name = "output"
type = "float"
